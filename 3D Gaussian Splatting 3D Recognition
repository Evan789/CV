
这是一个非常前沿且具有挑战性的项目。将 Gaussian Splatting (3DGS) 与 开放词汇 3D 语义理解 (Open-Vocabulary 3D Understanding) 结合是目前计算机视觉领域的研究热点（例如 LangSplat, CLIP-GS 等）。

鉴于你的环境非常新（PyTorch 2.6+），我们需要选择兼容性好且易于扩展的现代库。

A. 开发大纲与技术栈说明
为了实现从“视频”到“可识别语义的3D Gaussian场景”，我们需要构建一个流水线（Pipeline）。

1. 核心技术栈
3D 重建核心 (SOTA): gsplat 或 Nerfstudio。
理由： 原始的 Inria gaussian-splatting 代码库维护较慢。Nerfstudio 团队开发的 gsplat 是目前纯 CUDA/Python 加速最好的库，且更易于集成到 Python 项目中。
----------------------------------------------------
位姿估计 (SfM): COLMAP (必须) 或 HLOC。
理由： 3DGS 需要精确的相机位姿和稀疏点云初始化，目前 COLMAP 依然是工业标准。
----------------------------------------------------
3D 物体识别/语义理解: LangSAM (Language Segment Anything) 或 CLIP + SAM 2。
原理： 3DGS 本身只有颜色和几何。我们需要将渲染出的 2D 图像输入到 VLM (视觉语言模型) 中，获取掩码 (Mask)，然后反向投影 (Unproject) 回 3D 高斯球上。
-----------------------------------------------------
UI 交互框架: Gradio。
理由： 快速构建上传视频、查看 3D 模型和输入文字进行识别的 Web 界面。

深度学习框架: PyTorch 2.6.0。

----------------------------------------------------------------------------------------------------------------------------------------------------

2. 系统流程
数据预处理: 上传视频 -> ffmpeg 分帧 -> COLMAP 计算相机位姿 (Sparse Point Cloud)。
----------------------------------------------------------------------------------
3D 训练: 使用 gsplat 训练 Gaussian Splatting 模型，生成 .ply 文件。
----------------------------------------------------------------------------------
语义识别:
用户输入文本（如“苹果”）。
程序从特定视角渲染 2D 图像。
使用 GroundingDINO/CLIP 检测物体区域。
将 2D 区域映射回 3D 高斯点，高亮显示。
